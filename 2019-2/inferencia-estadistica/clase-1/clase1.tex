\documentclass{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\newtheorem{mydef}{Definition}
\newtheorem{mythm}{Theorem}
\newtheorem{myprf}{Proof}
\title{Clase 1: Inferencia Estadística}
\author{Justo Andrés Manrique Urbina}
\begin{document}
\maketitle
\begin{mydef}
Sean $(X_{1},X_{2},\ldots,X_{n})$ variables aleatorias, definidas en el espacio muestral, a partir de las cuales se realizará inferencia. Si estas variables son independientes y tienen la misma distribución que $X$, entonces se dice que se tiene una muestra aleatoria simple de $X$.
\end{mydef}
\begin{mydef}
	El parámetro desconocido $\theta$, que depende de la distribución de la muestra disponible $f(X_{1},X_{2},\ldots,X_{n})$, es desconocido. Sus posibles valores constituyen el conjunto $\Theta$.
\end{mydef}
\section{Ejemplo 1}
Sea $Y_{1}=\theta X_{1} + \varepsilon_{1},\ldots,Y_{n}=\theta X_{n} + \varepsilon_{n}$, dónde $(X_{1},X_{2},\ldots,X_{n})$ son cantidades conocidas. Asimismo, $\theta \in \mathbb{R}$ es una cantidad desconocida y $(\varepsilon_{1},\varepsilon_{2},\ldots,\varepsilon_{n})$ son variables aleatorias independientes con distribución $N(0,1)$.

Sea $(Y_{1},Y_{2},\ldots,Y_{n})$ una muestra aleatoria independiente, sin embargo no tienen la misma distribución, puesto que $Y_{i}\sim N(\theta X_{i},1)$.
\section{Ejemplo 2}
Sea $X_{i}=1$ si la unidad de observación $i$ satisface cierta característica y sea $X_{i}=0$ caso contrario, para $i=1,2,\ldots,n$. Sea $P(X_{i}=1)=\theta$ y $P(X_{i}=0)=1-\theta$ para $i=1,2,\ldots,n$. Dado lo anterior, se entiende que la distribución de $X_{i}$ es binomial de la forma $X_{i}\sim B(\theta)$.

Si asumimos que $(X_{1},X_{2},\ldots,X_{n})$ son independientes, entonces dicho vector es una muestra aleatoria simple de $X$, en dónde $X\sim B(\theta)$. \textbf{Ojo:} En términos prácticos, podemos definir $\theta$ como la proporción de unidades en una población que satisface la característica $i$.

\begin{mydef}
	La \textbf{estadística} es cualquier función de la muestra disponible $g(X_{1},X_{2},\ldots,X_{n})$. Usualmente $g$ es una función cuyo rango se encuentra en $\mathbb{R}^{n}$. Dicha estadística no debe depender de parámetros desconocidos.
\end{mydef}

\section{Ejemplos de la definición 3}
$$X_{(1)}=minimo{X_{1}, \ldots, X_{n}}$$
$$X_{(1)}=maximo{X_{1}, \ldots, X_{n}}$$
$$\sum_{j=1}=X_{j}$$
$$\frac{\sum_{j=1}=X_{j}}{n}$$ 

\begin{mydef}
Si $\theta$ es un parámetro, un estimador de $\theta$ es una estadística $\hat{\theta}=\hat{\theta}(X_{1},X_{2},\ldots,X_{n})$ que se utiliza para aproximar el valor desconocido de $\theta$. \textbf{Observación:} $\hat{\theta}$ es una variable aleatoria.
\end{mydef}

\section{Propiedades de un estimador}
\subsection{Insesgamiento}
$\hat{\theta}$ es un estimador insesgado de $\theta$, si se cumple lo siguiente:
\[ E(\hat{\theta})=\theta, \forall \theta \in \Theta.\]
\subsection{Ejemplo de insesgamiento}
El estimador usual de $\theta$ está dado por:
\[  \hat{\theta} = \frac{\sum_{j=1}X_{j}Y_{j}}{\sum_{j=1}X_{j}X_{j}}.\]
\[  E(\hat{\theta})=  \frac{\sum_{j=1}X_{j}E(Y_{j})}{\sum_{j=1}X_{j}X_{j}} = \theta.\]
Dado que $E(Y_{j}) = \theta X_{j}$. Por lo tanto, $\hat{\theta}$ es un estimador insesgado de $\theta$.

Por otro lado, se tiene que:
\[ E(\bar{g(x)})=E(g(x)).\]
\begin{myprf}
Ver a continuación la prueba:
\[ \bar{g(x)}= \frac{\sum_{j=1}g(X_{j})}{n}.\]
\[ E(\bar{g(x)})=  \frac{1}{n} \sum_{j=1} E(g(X_{j})).\]
\[ E(\bar{g(x)})=  \frac{1}{n} n \sum_{j=1} E(g(X)).\]
\[ E(g(X)).\]

\end{myprf}

\section{Ejemplo}
Sea $E(\bar{X^{2}}) = V(\bar{X}) + E^{2}(\bar{X})$. Entonces se tiene que:
\[ V(\frac{\sum_{j=1}^{n}X_{j}}{n}) + \mu^{2}.\]
\[ \frac{1}{n^{2}} \sum_{j=1}^{n}V(X_{j}) + \mu^{2}.\] Por independencia se tiene que $V(\sum) = \sum V()$.
\[  \frac{\sigma^{2}}{n} + \mu^{2}.\]
Luego, de (1), (2) y (3):
\[ E(S^{2})=  \frac{n}{n-1}[E(X^{2})- \ldots ].\]
\[  \frac{n}{n-1}[\sigma^{2}+\mu^{2}-( \frac{\sigma^{2}}{n} + \mu^{2})].\]
\[ \sigma^{2}.\]

Definición: Si $\lim_{n infinito} E(\hat{\theta})=\theta, \forall \theta \in \Theta$, se dice que $\hat{\theta}$ es asintóticamente insesgado.
\section{Propiedad de eficiencia}
Si $\hat{\theta_{1}}$ y $\hat{\theta_{1}}$ son estimadores insesgados de $\theta$, se dice que $\hat{\theta_{1}}$ es más eficiente que  $\hat{\theta_{1}}$ si $V(\hat{\theta_{1}}) < V(\hat{\theta_{2}})$.
\end{document}
